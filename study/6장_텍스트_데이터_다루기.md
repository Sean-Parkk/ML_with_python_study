# 6. 텍스트 데이터 다루기

- 텍스트 데이터의 경우, 숫자형과 특성이 매우 다름
- 길이나 형식 등이 같은 경우가 거의 없음, 모델을 만들기 전에 전처리를 해줘야함

### 문자열 데이터 타입

1. 범주형 데이터
    - 빨강, 초록, 흰색

2. 범주에 의미를 연결시킬 수 있는 임의의 문자열
    - 갈색, 브라운, 바위색, 암갈색, 흙색
3. 구조화된 문자열 데이터
    - 주소, 장소, 사람 이름, 날짜 등 일정한 구조로 되어있는 것
4. 텍스트 데이터
    - 트윗, 각종 리뷰 같은 데이터
    - 데이터셋: 말뭉치(corpus)
    - 각 데이터 포인트: 문서(document)
    - 이런 용어들은 정보 검색(IR, information retrieval)과 자연어 처리(NLP, natural language processing)공동체에서 유래

### 텍스트 데이터를 BOW로 표현하기

- BOW(bag of words)
    - 머신러닝에서 텍스트를 표현하는 방법
    - 장, 문단, 서식과 같은 텍스트의 구조 대부분은 잃음
    - 각 단어가 이 말뭉치에 있는 텍스트에 얼마나 많이 나타나는지만 살펴봄
- BOW의 순서
    1. 토큰화(tokenization)
        - 문서에 포함된 단어(토큰)를 기준점(쉼표나 띄어쓰기 등)으로 구분하여 나눔
    2. 어휘 사전 구축
        - 모든 문서에 나타난 모든 단어의 어휘를 모으고 번호를 매김(알파벳 순)
    3. 인코딩
        - 어휘 사전의 단어가 문서마다 몇 번 나타나는지 빈도 측정
    - BOW 표현은 CountVectorizer에 구현되어 있음
        - fit 메서드 적용 시, 훈련 데이터를 토큰으로 나누고, 어휘 사전을 구축하여 vocabulary_ 속성에 저장
- CountVectorizer
    - 불필요한 단어를 많이 저장할 수도 있음.
    - 이럴 때 min_df를 지정하여 개선 가능!
        - min_df: 토큰이 나타날 최소 문서 수 지정
        - 성능에 큰 영향을 끼치지는 않을 수 있지만, 속도를 개선해주고 모델을 이해하는데 조금 더 쉬워진다.

### 불용어

-
